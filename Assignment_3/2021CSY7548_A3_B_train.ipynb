{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "2021CSY7548_A3_B_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWjwfx8T5OAJ"
      },
      "source": [
        "Make a copy of this notebook and rename using your USERID in the following format, 2017CSZ8058\n",
        "\n",
        "Give read access to keshavkolluru@gmail.com, vishalsaley114@gmail.com and kartikeya.badola@gmail.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dUh7EUv9ujL",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:20:22.742760Z",
          "iopub.execute_input": "2021-10-22T13:20:22.743214Z",
          "iopub.status.idle": "2021-10-22T13:20:26.643922Z",
          "shell.execute_reply.started": "2021-10-22T13:20:22.743178Z",
          "shell.execute_reply": "2021-10-22T13:20:26.643095Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f227605-f281-42a7-c388-f2bfd442550d"
      },
      "source": [
        "## DONT CHANGE THIS CELL\n",
        "!wget http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-25 08:22:54--  http://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/data.zip\n",
            "Resolving www.cse.iitd.ac.in (www.cse.iitd.ac.in)... 103.27.9.152\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/data.zip [following]\n",
            "--2021-10-25 08:22:55--  https://www.cse.iitd.ac.in/~mausam/courses/col772/autumn2021/A3/data.zip\n",
            "Connecting to www.cse.iitd.ac.in (www.cse.iitd.ac.in)|103.27.9.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 217313 (212K) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>] 212.22K   111KB/s    in 1.9s    \n",
            "\n",
            "2021-10-25 08:22:58 (111 KB/s) - ‘data.zip’ saved [217313/217313]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hahqIn6yO_Md",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:20:03.169570Z",
          "iopub.execute_input": "2021-10-22T13:20:03.170016Z",
          "iopub.status.idle": "2021-10-22T13:20:19.319835Z",
          "shell.execute_reply.started": "2021-10-22T13:20:03.169933Z",
          "shell.execute_reply": "2021-10-22T13:20:19.319018Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4485a672-b695-4fc1-f96c-cb44f4a771e6"
      },
      "source": [
        "!pip3 install Sentencepiece\n",
        "!pip3 install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: Sentencepiece\n",
            "Successfully installed Sentencepiece-0.1.96\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 48.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 18.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.19 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgPPsZzEHeDq"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDv8uRYkHcxs",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:20:26.645940Z",
          "iopub.execute_input": "2021-10-22T13:20:26.646190Z",
          "iopub.status.idle": "2021-10-22T13:20:28.949403Z",
          "shell.execute_reply.started": "2021-10-22T13:20:26.646156Z",
          "shell.execute_reply": "2021-10-22T13:20:28.948535Z"
        },
        "trusted": true
      },
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "import datetime\n",
        "from torchtext.legacy import data as torchtext_data\n",
        "from torchtext import datasets\n",
        "from torchtext.vocab import Vectors, GloVe, FastText\n",
        "\n",
        "from transformers import BertTokenizer, BertTokenizerFast, BertForSequenceClassification,BertConfig, BertModel\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcGamhkB9fuK"
      },
      "source": [
        "# **Prepare data csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNkGgBrlHr_m",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:20:28.951163Z",
          "iopub.execute_input": "2021-10-22T13:20:28.951400Z",
          "iopub.status.idle": "2021-10-22T13:20:30.276193Z",
          "shell.execute_reply.started": "2021-10-22T13:20:28.951369Z",
          "shell.execute_reply": "2021-10-22T13:20:30.274905Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad4d8e94-3558-41ed-ef4e-5dad36b0730b"
      },
      "source": [
        "!mkdir model\n",
        "!unzip /content/data.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/data.zip\n",
            "   creating: data/\n",
            "   creating: data/train/\n",
            "  inflating: data/train/train.gold.txt  \n",
            "  inflating: data/train/train.data.txt  \n",
            "   creating: data/validation/\n",
            "  inflating: data/validation/validation.data.txt  \n",
            "  inflating: data/validation/validation.gold.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYbRGjDw1vm8",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:20:30.278309Z",
          "iopub.execute_input": "2021-10-22T13:20:30.278854Z",
          "iopub.status.idle": "2021-10-22T13:20:30.386390Z",
          "shell.execute_reply.started": "2021-10-22T13:20:30.278812Z",
          "shell.execute_reply": "2021-10-22T13:20:30.385640Z"
        },
        "trusted": true
      },
      "source": [
        "with open(\"/content/data/train/train.data.txt\",\"r\") as f:\n",
        "  train_data = f.read()\n",
        "with open(\"/content/data/train/train.gold.txt\",\"r\") as f:\n",
        "  train_labels = f.readlines()\n",
        "\n",
        "c=0\n",
        "dataset = []\n",
        "temp = {\"sent1\":\"\",\"sent2\":\"\",\"word\":\"\",\"pos1\":0,\"pos2\":0,\"label\":0,\"pos_tag\":\"\"}\n",
        "for data in train_data.split(\"\\n\"):\n",
        "  if(data != ''):\n",
        "      temp = {\"sent1\":\"\",\"sent2\":\"\",\"word\":\"\",\"pos1\":0,\"pos2\":0,\"label\":0}\n",
        "      temp[\"text\"] = data.split(\"\\t\")[3] + \" [SEP] \" + data.split(\"\\t\")[4]\n",
        "      temp[\"sent1\"] = data.split(\"\\t\")[3]\n",
        "      temp[\"sent2\"] = data.split(\"\\t\")[4]\n",
        "      temp[\"pos1\"] = int(data.split(\"\\t\")[2].split(\"-\")[0])\n",
        "      temp[\"pos2\"] = int(data.split(\"\\t\")[2].split(\"-\")[1])\n",
        "      temp[\"word\"] = data.split(\"\\t\")[0]\n",
        "      temp[\"pos_tag\"] = data.split(\"\\t\")[1]\n",
        "      temp[\"label\"] = 1 if (train_labels[c].strip() in [\"T\",\"t\"]) else 0\n",
        "      dataset.append(temp)\n",
        "      c += 1\n",
        "\n",
        "pd.DataFrame(dataset).to_csv(\"/content/train_data.tsv\",sep=\"\\t\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFH20ac1-12r",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:20:30.388909Z",
          "iopub.execute_input": "2021-10-22T13:20:30.389110Z",
          "iopub.status.idle": "2021-10-22T13:20:30.414705Z",
          "shell.execute_reply.started": "2021-10-22T13:20:30.389087Z",
          "shell.execute_reply": "2021-10-22T13:20:30.414059Z"
        },
        "trusted": true
      },
      "source": [
        "with open(\"/content/data/validation/validation.data.txt\",\"r\") as f:\n",
        "  validation_data = f.read()\n",
        "with open(\"/content/data/validation/validation.gold.txt\",\"r\") as f:\n",
        "  validation_labels = f.readlines()\n",
        "\n",
        "c=0\n",
        "dataset = []\n",
        "temp = {\"sent1\":\"\",\"sent2\":\"\",\"word\":\"\",\"pos1\":0,\"pos2\":0,\"label\":0}\n",
        "for data in validation_data.split(\"\\n\"):\n",
        "  if(data != ''):\n",
        "      temp = {\"sent1\":\"\",\"sent2\":\"\",\"word\":\"\",\"pos1\":0,\"pos2\":0,\"label\":0}\n",
        "      temp[\"text\"] = data.split(\"\\t\")[3] + \" [SEP] \" + data.split(\"\\t\")[4]\n",
        "      temp[\"sent1\"] = data.split(\"\\t\")[3]\n",
        "      temp[\"sent2\"] = data.split(\"\\t\")[4]\n",
        "      temp[\"pos1\"] = int(data.split(\"\\t\")[2].split(\"-\")[0])\n",
        "      temp[\"pos2\"] = int(data.split(\"\\t\")[2].split(\"-\")[1])\n",
        "      temp[\"word\"] = data.split(\"\\t\")[0]\n",
        "      temp[\"pos_tag\"] = data.split(\"\\t\")[1]\n",
        "      temp[\"label\"] = 1 if (validation_labels[c].strip() in [\"T\",\"t\"]) else 0\n",
        "      dataset.append(temp)\n",
        "      c += 1\n",
        "\n",
        "pd.DataFrame(dataset).to_csv(\"/content/validation_data.tsv\",sep=\"\\t\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czRR9a7myiIy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r0SrepKqBVZ"
      },
      "source": [
        "# **NLTK WORDNET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:07.955578Z",
          "iopub.execute_input": "2021-10-22T13:21:07.956222Z",
          "iopub.status.idle": "2021-10-22T13:21:07.959738Z",
          "shell.execute_reply.started": "2021-10-22T13:21:07.956183Z",
          "shell.execute_reply": "2021-10-22T13:21:07.959040Z"
        },
        "trusted": true,
        "id": "dqvwEOxhqBVZ"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dGzlqHuQakB",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:08.625321Z",
          "iopub.execute_input": "2021-10-22T13:21:08.625893Z",
          "iopub.status.idle": "2021-10-22T13:21:09.257213Z",
          "shell.execute_reply.started": "2021-10-22T13:21:08.625851Z",
          "shell.execute_reply": "2021-10-22T13:21:09.256475Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54bb34ed-d3c9-46ed-adf9-c78c9431d81d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:09.720092Z",
          "iopub.execute_input": "2021-10-22T13:21:09.720695Z",
          "iopub.status.idle": "2021-10-22T13:21:09.726934Z",
          "shell.execute_reply.started": "2021-10-22T13:21:09.720656Z",
          "shell.execute_reply": "2021-10-22T13:21:09.724139Z"
        },
        "trusted": true,
        "id": "tYn3sNr2qBVa"
      },
      "source": [
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:45.640632Z",
          "iopub.execute_input": "2021-10-22T13:21:45.640911Z",
          "iopub.status.idle": "2021-10-22T13:21:54.369865Z",
          "shell.execute_reply.started": "2021-10-22T13:21:45.640884Z",
          "shell.execute_reply": "2021-10-22T13:21:54.369090Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "RlBzsjEMqBVa",
        "outputId": "8ee4582e-aa65-4166-b4a8-481b3989e6e2"
      },
      "source": [
        "from tqdm import tqdm\n",
        "all_synset = []\n",
        "for synset in tqdm(list(wn.all_synsets())):\n",
        "    try:\n",
        "        n = synset.name()\n",
        "        all_synset.append({\"name\":n.split(\".\")[0], \"pos\":n.split(\".\")[1], \"num\":int(n.split(\".\")[2])})\n",
        "    except Exception as e:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-60-44d65b81369e>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    positive_samples = []\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:54.371350Z",
          "iopub.execute_input": "2021-10-22T13:21:54.371694Z",
          "iopub.status.idle": "2021-10-22T13:21:54.492476Z",
          "shell.execute_reply.started": "2021-10-22T13:21:54.371650Z",
          "shell.execute_reply": "2021-10-22T13:21:54.491735Z"
        },
        "trusted": true,
        "id": "0FrxkdjbqBVa"
      },
      "source": [
        "noun_synsets = pd.DataFrame(all_synset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:54.494015Z",
          "iopub.execute_input": "2021-10-22T13:21:54.494330Z",
          "iopub.status.idle": "2021-10-22T13:21:54.503497Z",
          "shell.execute_reply.started": "2021-10-22T13:21:54.494281Z",
          "shell.execute_reply": "2021-10-22T13:21:54.502814Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "lKyq3CN2qBVb",
        "outputId": "f03f7a04-01d8-4a5e-f966-442bf97ceb09"
      },
      "source": [
        "noun_synsets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>pos</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68589</th>\n",
              "      <td>'hood</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103017</th>\n",
              "      <td>1530s</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65698</th>\n",
              "      <td>15_may_organization</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103029</th>\n",
              "      <td>1750s</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103033</th>\n",
              "      <td>1760s</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       name pos  num\n",
              "68589                 'hood   n    1\n",
              "103017                1530s   n    1\n",
              "65698   15_may_organization   n    1\n",
              "103029                1750s   n    1\n",
              "103033                1760s   n    1"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:54.505810Z",
          "iopub.execute_input": "2021-10-22T13:21:54.506286Z",
          "iopub.status.idle": "2021-10-22T13:21:54.723211Z",
          "shell.execute_reply.started": "2021-10-22T13:21:54.506250Z",
          "shell.execute_reply": "2021-10-22T13:21:54.722469Z"
        },
        "trusted": true,
        "id": "VdpsKDgjqBVb"
      },
      "source": [
        "noun_synsets.sort_values([\"name\",\"pos\",\"num\"], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:54.724367Z",
          "iopub.execute_input": "2021-10-22T13:21:54.725038Z",
          "iopub.status.idle": "2021-10-22T13:21:54.736765Z",
          "shell.execute_reply.started": "2021-10-22T13:21:54.724994Z",
          "shell.execute_reply": "2021-10-22T13:21:54.735754Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Rs6TUCeEqBVb",
        "outputId": "78fcab8e-1387-419b-cdcb-79c3a9aefa06"
      },
      "source": [
        "noun_synsets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>pos</th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>68589</th>\n",
              "      <td>'hood</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103017</th>\n",
              "      <td>1530s</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65698</th>\n",
              "      <td>15_may_organization</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103029</th>\n",
              "      <td>1750s</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103033</th>\n",
              "      <td>1760s</td>\n",
              "      <td>n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       name pos  num\n",
              "68589                 'hood   n    1\n",
              "103017                1530s   n    1\n",
              "65698   15_may_organization   n    1\n",
              "103029                1750s   n    1\n",
              "103033                1760s   n    1"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:54.738051Z",
          "iopub.execute_input": "2021-10-22T13:21:54.738383Z",
          "iopub.status.idle": "2021-10-22T13:21:54.775047Z",
          "shell.execute_reply.started": "2021-10-22T13:21:54.738344Z",
          "shell.execute_reply": "2021-10-22T13:21:54.774297Z"
        },
        "trusted": true,
        "id": "cM6niIfdqBVb"
      },
      "source": [
        "noun_synsets.drop_duplicates([\"name\"], keep=\"first\", inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:54.776675Z",
          "iopub.execute_input": "2021-10-22T13:21:54.777083Z",
          "iopub.status.idle": "2021-10-22T13:21:57.077109Z",
          "shell.execute_reply.started": "2021-10-22T13:21:54.777046Z",
          "shell.execute_reply": "2021-10-22T13:21:57.076221Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM9UyczaqBVc",
        "outputId": "0e99662a-a0c0-49fe-fd10-a32103863e0b"
      },
      "source": [
        "reg = re.compile(r\"[^a-zA-Z]\")\n",
        "\n",
        "negative_samples = []\n",
        "positive_samples = []\n",
        "for row in tqdm(noun_synsets.to_dict(\"records\")[:]):\n",
        "    temp_neg = []\n",
        "    if(True):\n",
        "        for i in range(100):\n",
        "            try:\n",
        "                if(not reg.search(row[\"name\"])):\n",
        "                    examples = wn.synset(f'{row[\"name\"]}.{row[\"pos\"]}.{i}').examples()\n",
        "                    pos_examples = [i for i in examples if row[\"name\"] in i ]\n",
        "                    if (len(pos_examples)) > 1:\n",
        "                        s = list(itertools.permutations(pos_examples,2))\n",
        "                        s = [tuple(sorted(i)) for i in s]\n",
        "                        s = list(set(s))\n",
        "                        positive_samples.extend(s)\n",
        "                    for j in examples:\n",
        "                        if(row[\"name\"] in j):\n",
        "                            temp_neg.append(j)\n",
        "                            break\n",
        "            except Exception as e:\n",
        "                break\n",
        "        s = []\n",
        "        if(len(temp_neg)>2):\n",
        "            s = list(itertools.permutations(temp_neg,2))[:]\n",
        "            s = [tuple(sorted(i)) for i in s][:]\n",
        "            s = list(set(s))\n",
        "        if(s != []):\n",
        "            negative_samples.extend(s)\n",
        "            temp_neg = []"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 86547/86547 [00:02<00:00, 36583.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.078422Z",
          "iopub.execute_input": "2021-10-22T13:21:57.078772Z",
          "iopub.status.idle": "2021-10-22T13:21:57.085322Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.078732Z",
          "shell.execute_reply": "2021-10-22T13:21:57.084479Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUHkU1_iqBVc",
        "outputId": "15cd2960-1150-4507-df9b-12afe60a6a93"
      },
      "source": [
        "len(positive_samples), len(negative_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11881, 26437)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.098627Z",
          "iopub.execute_input": "2021-10-22T13:21:57.099244Z",
          "iopub.status.idle": "2021-10-22T13:21:57.114280Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.099204Z",
          "shell.execute_reply": "2021-10-22T13:21:57.113494Z"
        },
        "trusted": true,
        "id": "EFHVhS6fqBVd"
      },
      "source": [
        "positive_samples = [i for i in positive_samples if i[0]!=i[1]]\n",
        "negative_samples = [i for i in negative_samples if i[0]!=i[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.115342Z",
          "iopub.execute_input": "2021-10-22T13:21:57.116110Z",
          "iopub.status.idle": "2021-10-22T13:21:57.126094Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.116077Z",
          "shell.execute_reply": "2021-10-22T13:21:57.125393Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5d_tivfqBVd",
        "outputId": "c48c8b33-a2ad-45e2-d3b1-9fdcab2bbea3"
      },
      "source": [
        "len(positive_samples), len(negative_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11881, 22786)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.127611Z",
          "iopub.execute_input": "2021-10-22T13:21:57.128150Z",
          "iopub.status.idle": "2021-10-22T13:21:57.137365Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.128113Z",
          "shell.execute_reply": "2021-10-22T13:21:57.136622Z"
        },
        "trusted": true,
        "id": "QMwKdDNvqBVd"
      },
      "source": [
        "ps = pd.DataFrame(positive_samples, columns=[\"sent1\",\"sent2\"])\n",
        "ps[\"label\"] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.138764Z",
          "iopub.execute_input": "2021-10-22T13:21:57.139253Z",
          "iopub.status.idle": "2021-10-22T13:21:57.151491Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.139197Z",
          "shell.execute_reply": "2021-10-22T13:21:57.150520Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qq3JWBhjqBVd",
        "outputId": "5df6eeee-8ece-4417-f010-8398ddd24a7e"
      },
      "source": [
        "ps.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abject poverty</td>\n",
              "      <td>the most abject slaves joined in the revolt</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>an able seaman</td>\n",
              "      <td>every able-bodied young man served in the army</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>able to swim</td>\n",
              "      <td>she was able to program her computer</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she was able to program her computer</td>\n",
              "      <td>we were at last able to buy a car</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>able to get a grant for the project</td>\n",
              "      <td>we were at last able to buy a car</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sent1  ... label\n",
              "0                        abject poverty  ...     1\n",
              "1                        an able seaman  ...     1\n",
              "2                          able to swim  ...     1\n",
              "3  she was able to program her computer  ...     1\n",
              "4   able to get a grant for the project  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.152992Z",
          "iopub.execute_input": "2021-10-22T13:21:57.153316Z",
          "iopub.status.idle": "2021-10-22T13:21:57.164561Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.153282Z",
          "shell.execute_reply": "2021-10-22T13:21:57.163845Z"
        },
        "trusted": true,
        "id": "CYTncdi_qBVd"
      },
      "source": [
        "ns = pd.DataFrame(negative_samples, columns=[\"sent1\",\"sent2\"])\n",
        "ns[\"label\"] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.165776Z",
          "iopub.execute_input": "2021-10-22T13:21:57.166331Z",
          "iopub.status.idle": "2021-10-22T13:21:57.178881Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.166293Z",
          "shell.execute_reply": "2021-10-22T13:21:57.178010Z"
        },
        "trusted": true,
        "id": "fu8agPPXqBVe"
      },
      "source": [
        "wordnet_data = pd.DataFrame()\n",
        "wordnet_data = wordnet_data.append(ps)\n",
        "wordnet_data = wordnet_data.append(ns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.181797Z",
          "iopub.execute_input": "2021-10-22T13:21:57.182171Z",
          "iopub.status.idle": "2021-10-22T13:21:57.763107Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.182138Z",
          "shell.execute_reply": "2021-10-22T13:21:57.762367Z"
        },
        "trusted": true,
        "id": "C0sgnaTfqBVe"
      },
      "source": [
        "wordnet_data[\"text\"] = wordnet_data.apply(lambda x : x[\"sent1\"]+\". [SEP] \"+x[\"sent2\"]+\".\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.764490Z",
          "iopub.execute_input": "2021-10-22T13:21:57.764785Z",
          "iopub.status.idle": "2021-10-22T13:21:57.774710Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.764740Z",
          "shell.execute_reply": "2021-10-22T13:21:57.773977Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VbUJuBIxqBVe",
        "outputId": "4b90ce00-c075-493b-c371-ff39a435aa17"
      },
      "source": [
        "wordnet_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sent1</th>\n",
              "      <th>sent2</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>abject poverty</td>\n",
              "      <td>the most abject slaves joined in the revolt</td>\n",
              "      <td>1</td>\n",
              "      <td>abject poverty. [SEP] the most abject slaves j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>an able seaman</td>\n",
              "      <td>every able-bodied young man served in the army</td>\n",
              "      <td>1</td>\n",
              "      <td>an able seaman. [SEP] every able-bodied young ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>able to swim</td>\n",
              "      <td>she was able to program her computer</td>\n",
              "      <td>1</td>\n",
              "      <td>able to swim. [SEP] she was able to program he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>she was able to program her computer</td>\n",
              "      <td>we were at last able to buy a car</td>\n",
              "      <td>1</td>\n",
              "      <td>she was able to program her computer. [SEP] we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>able to get a grant for the project</td>\n",
              "      <td>we were at last able to buy a car</td>\n",
              "      <td>1</td>\n",
              "      <td>able to get a grant for the project. [SEP] we ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  sent1  ...                                               text\n",
              "0                        abject poverty  ...  abject poverty. [SEP] the most abject slaves j...\n",
              "1                        an able seaman  ...  an able seaman. [SEP] every able-bodied young ...\n",
              "2                          able to swim  ...  able to swim. [SEP] she was able to program he...\n",
              "3  she was able to program her computer  ...  she was able to program her computer. [SEP] we...\n",
              "4   able to get a grant for the project  ...  able to get a grant for the project. [SEP] we ...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:21:57.776205Z",
          "iopub.execute_input": "2021-10-22T13:21:57.776720Z",
          "iopub.status.idle": "2021-10-22T13:21:58.015162Z",
          "shell.execute_reply.started": "2021-10-22T13:21:57.776663Z",
          "shell.execute_reply": "2021-10-22T13:21:58.014276Z"
        },
        "trusted": true,
        "id": "n_37jiLbqBVe"
      },
      "source": [
        "wordnet_data.to_csv(\"./wordnet_train.tsv\",sep=\"\\t\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRn5GMgvAz9"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O65HNHLvHOq"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from transformers import AlbertConfig, AlbertModel, AlbertTokenizer\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AlbertForSequenceClassification, AdamW, AlbertConfig\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:22:21.060906Z",
          "iopub.execute_input": "2021-10-22T13:22:21.061401Z",
          "iopub.status.idle": "2021-10-22T13:22:21.158239Z",
          "shell.execute_reply.started": "2021-10-22T13:22:21.061361Z",
          "shell.execute_reply": "2021-10-22T13:22:21.157355Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHiRHaYZqBVQ",
        "outputId": "5c5196ac-b241-401e-da62-80dd9ce32a3f"
      },
      "source": [
        "all_data = pd.read_csv(\"./train_data.tsv\", sep=\"\\t\")\n",
        "wordnet_data = pd.read_csv(\"./wordnet_train.tsv\", sep=\"\\t\")\n",
        "validation_data = pd.read_csv(\"./validation_data.tsv\", sep=\"\\t\")\n",
        "print(all_data.shape)\n",
        "all_data = all_data.append(wordnet_data)\n",
        "all_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5428, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40095, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6FDSrJRSfjZ",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:22:49.996264Z",
          "iopub.execute_input": "2021-10-22T13:22:49.996534Z",
          "iopub.status.idle": "2021-10-22T13:22:53.222956Z",
          "shell.execute_reply.started": "2021-10-22T13:22:49.996505Z",
          "shell.execute_reply": "2021-10-22T13:22:53.222188Z"
        },
        "trusted": true
      },
      "source": [
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-22T13:23:05.133660Z",
          "iopub.execute_input": "2021-10-22T13:23:05.134046Z",
          "iopub.status.idle": "2021-10-22T13:23:05.190685Z",
          "shell.execute_reply.started": "2021-10-22T13:23:05.134005Z",
          "shell.execute_reply": "2021-10-22T13:23:05.189911Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oaJGswQfqBVT",
        "outputId": "d171f3b4-6007-47d1-ab48-b0d220865f59"
      },
      "source": [
        "device = \"cpu\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qwmQLDKRO96",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:23:09.090271Z",
          "iopub.execute_input": "2021-10-22T13:23:09.090531Z",
          "iopub.status.idle": "2021-10-22T13:23:23.484118Z",
          "shell.execute_reply.started": "2021-10-22T13:23:09.090501Z",
          "shell.execute_reply": "2021-10-22T13:23:23.482560Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c53a2e-4410-4eab-9ee6-e64239acfc95"
      },
      "source": [
        "def prepare_input_data(all_data):\n",
        "    \n",
        "    tokenized_text = []\n",
        "    attention_masks = []\n",
        "    labels = []\n",
        "\n",
        "    for sentence in all_data[\"text\"].tolist():\n",
        "        encoded_dict = tokenizer.encode_plus(sentence, add_special_tokens = True, max_length = 64, pad_to_max_length = True,\\\n",
        "                                             return_attention_mask = True, return_tensors = 'pt')\n",
        "\n",
        "        tokenized_text.append(encoded_dict['input_ids'])    \n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    tokenized_text = torch.cat(tokenized_text, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    labels = torch.tensor(all_data[\"label\"].tolist())\n",
        "    \n",
        "    return tokenized_text, attention_masks, labels\n",
        "\n",
        "train_tokenized_text, train_attention_masks, train_labels = prepare_input_data(all_data)\n",
        "val_tokenized_text, val_attention_masks, val_labels = prepare_input_data(validation_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMrgW9OfRO97",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:26:00.556468Z",
          "iopub.execute_input": "2021-10-22T13:26:00.557038Z",
          "iopub.status.idle": "2021-10-22T13:26:00.565762Z",
          "shell.execute_reply.started": "2021-10-22T13:26:00.556997Z",
          "shell.execute_reply": "2021-10-22T13:26:00.564717Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57e99025-c6dd-4733-ac0c-fa7cffa088c9"
      },
      "source": [
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "learning_rate = 0.00002\n",
        "model_name = \"albert-base-v2\"\n",
        "\n",
        "train_dataset = TensorDataset(train_tokenized_text, train_attention_masks, train_labels)\n",
        "val_dataset = TensorDataset(val_tokenized_text, val_attention_masks, val_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,  sampler = RandomSampler(train_dataset), batch_size = batch_size )\n",
        "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size )\n",
        "\n",
        "model = AlbertForSequenceClassification.from_pretrained(model_name, num_labels = 2)\n",
        "optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight', 'predictions.dense.weight', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlHNprETqBVW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FjmlU9zq_Cs"
      },
      "source": [
        "## Basic training loop\n",
        "\n",
        "t0 = time.time()\n",
        "def get_logit_classification_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "class Train():\n",
        "    def __init__(self,model, optimiser, train_iterator, validation_iterator,  device=\"cuda\",epochs=5):\n",
        "        print(\"program execution start: {}\".format(datetime.datetime.now()))\n",
        "        self.model = model\n",
        "        self.optimiser = optimiser\n",
        "        self.best_val_acc = None\n",
        "        self.epochs = epochs\n",
        "        self.train_iterator = train_iterator\n",
        "        self.validation_iterator = validation_iterator\n",
        "        self.scheduler = get_linear_schedule_with_warmup(self.optimiser, num_warmup_steps = 0, num_training_steps = len(self.train_iterator) * self.epochs)\n",
        "        # self.scheduler = torch.optim.lr_scheduler.StepLR(self.optimiser, step_size=5, gamma=0.5)\n",
        "        self.device=device\n",
        "        self.model.to(self.device)\n",
        "\n",
        "        print(\"resource preparation done: {}\".format(datetime.datetime.now()))\n",
        "\n",
        "    def result_checkpoint(self, epoch, train_loss, val_loss, train_acc, val_acc, took):\n",
        "        if self.best_val_acc is None or val_acc > self.best_val_acc:\n",
        "          self.best_val_acc = val_acc\n",
        "          torch.save({\n",
        "            'accuracy': self.best_val_acc,\n",
        "            'model_dict': self.model.state_dict(),\n",
        "          }, '/content/model/weight_params.pt')\n",
        "        print('| Epoch {:3d} | train loss {:5.2f} | train acc {:5.2f} | val loss {:5.2f} | val acc {:5.2f} | time: {:5.2f}s |'\n",
        "            .format(epoch, train_loss, train_acc, val_loss, val_acc, took))\n",
        "  \n",
        "    def train(self):\n",
        "        self.model.train(); \n",
        "    \n",
        "        n_total, n_loss, n_acc = 0, 0, 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(self.train_iterator):\n",
        "            if(batch_idx%50 == 0):\n",
        "              print(f\"Done for batch {batch_idx} : {time.time()-t0}\")\n",
        "            self.optimiser.zero_grad()\n",
        "#             torch.cuda.empty_cache()\n",
        "            \n",
        "            tokenized_text = batch[0].to(device)\n",
        "            att_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "\n",
        "            output = self.model(tokenized_text, attention_mask=att_mask, labels=labels)\n",
        "          \n",
        "            logits = output.logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            n_loss += output.loss\n",
        "            n_acc += get_logit_classification_accuracy(logits, label_ids)\n",
        "            n_total += len(batch)\n",
        "            \n",
        "            output.loss.backward(); \n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimiser.step()\n",
        "#             self.scheduler.step()\n",
        "\n",
        "        train_loss = n_loss/n_total\n",
        "        train_acc = n_acc/len(self.train_iterator)\n",
        "        return train_loss, train_acc\n",
        "\n",
        "    def validate(self):\n",
        "        self.model.eval();\n",
        "        n_total, n_loss, n_acc = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(self.validation_iterator):\n",
        "                tokenized_text = batch[0].to(device)\n",
        "                att_mask = batch[1].to(device)\n",
        "                labels = batch[2].to(device)\n",
        "\n",
        "                output = self.model(tokenized_text, attention_mask=att_mask, labels=labels)\n",
        "          \n",
        "                logits = output.logits.detach().cpu().numpy()\n",
        "                label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "                n_loss += output.loss\n",
        "                n_acc += get_logit_classification_accuracy(logits, label_ids)\n",
        "                n_total += len(batch)\n",
        "#                 del output\n",
        "#                 torch.cuda.empty_cache()\n",
        "\n",
        "        val_loss = n_loss/n_total\n",
        "        val_acc = n_acc/len(self.validation_iterator)\n",
        "        return val_loss, val_acc\n",
        "\n",
        "    def execute(self):\n",
        "        print(\" [*] Training starts!\")\n",
        "        print('-' * 99)\n",
        "        for epoch in range(1, self.epochs+1):\n",
        "            start = time.time()\n",
        "\n",
        "            train_loss, train_acc = self.train()\n",
        "            val_loss, val_acc = self.validate()\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            took = time.time()-start\n",
        "            self.result_checkpoint(epoch, train_loss, val_loss, train_acc, val_acc, took)\n",
        "\n",
        "            print('| Epoch {:3d} | train loss {:6.2f} | train acc {:6.3f} | val loss {:6.3f} | val acc {:6.3f} | time: {:5.2f}s |'.format(\n",
        "              epoch, train_loss, train_acc, val_loss, round(val_acc,5), took))\n",
        "        self.finish()\n",
        "\n",
        "    def finish(self):\n",
        "        # self.logger.info(\"[*] Training finished!\\n\\n\")\n",
        "        print('-' * 99)\n",
        "        print(\" [*] Training finished!\")\n",
        "        print(\" [*] Please find the saved model and training log in results_dir\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF3UzfIXRO98",
        "execution": {
          "iopub.status.busy": "2021-10-22T13:26:05.720293Z",
          "iopub.execute_input": "2021-10-22T13:26:05.720563Z",
          "iopub.status.idle": "2021-10-22T13:26:19.698323Z",
          "shell.execute_reply.started": "2021-10-22T13:26:05.720532Z",
          "shell.execute_reply": "2021-10-22T13:26:19.697546Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b89d9bdf-72a0-43f6-e306-a102928d62c0"
      },
      "source": [
        "t0=time.time()\n",
        "task = Train(model, optimizer, train_dataloader, validation_dataloader, device, epochs=epochs)\n",
        "task.execute()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "program execution start: 2021-10-25 10:01:12.688163\n",
            "resource preparation done: 2021-10-25 10:01:12.705639\n",
            " [*] Training starts!\n",
            "---------------------------------------------------------------------------------------------------\n",
            "Done for batch 0 : 0.02172064781188965\n",
            "Done for batch 50 : 33.07676100730896\n",
            "Done for batch 100 : 66.44710779190063\n",
            "Done for batch 150 : 99.80544853210449\n",
            "Done for batch 200 : 133.11739587783813\n",
            "Done for batch 250 : 166.3997824192047\n",
            "Done for batch 300 : 199.6916823387146\n",
            "Done for batch 350 : 232.98297667503357\n",
            "Done for batch 400 : 266.2874939441681\n",
            "Done for batch 450 : 299.57717394828796\n",
            "Done for batch 500 : 332.8601531982422\n",
            "Done for batch 550 : 366.1332778930664\n",
            "Done for batch 600 : 399.44477915763855\n",
            "Done for batch 650 : 432.7529876232147\n",
            "Done for batch 700 : 466.0480296611786\n",
            "Done for batch 750 : 499.34239315986633\n",
            "Done for batch 800 : 532.6109800338745\n",
            "Done for batch 850 : 565.8955442905426\n",
            "Done for batch 900 : 599.1945734024048\n",
            "Done for batch 950 : 632.4643664360046\n",
            "Done for batch 1000 : 665.7722067832947\n",
            "Done for batch 1050 : 699.0647943019867\n",
            "Done for batch 1100 : 732.3601715564728\n",
            "Done for batch 1150 : 765.6436944007874\n",
            "Done for batch 1200 : 798.9413838386536\n",
            "Done for batch 1250 : 832.2158236503601\n",
            "| Epoch   1 | train loss  0.17 | train acc  0.74 | val loss  0.21 | val acc  0.66 | time: 839.07s |\n",
            "| Epoch   1 | train loss   0.17 | train acc  0.736 | val loss  0.210 | val acc  0.660 | time: 839.07s |\n",
            "Done for batch 0 : 839.1982414722443\n",
            "Done for batch 50 : 872.4690880775452\n",
            "Done for batch 100 : 905.7409424781799\n",
            "Done for batch 150 : 939.0119712352753\n",
            "Done for batch 200 : 972.3215019702911\n",
            "Done for batch 250 : 1005.6101121902466\n",
            "Done for batch 300 : 1038.9043111801147\n",
            "Done for batch 350 : 1072.2100660800934\n",
            "Done for batch 400 : 1105.4855561256409\n",
            "Done for batch 450 : 1138.7575378417969\n",
            "Done for batch 500 : 1172.0580978393555\n",
            "Done for batch 550 : 1205.3380160331726\n",
            "Done for batch 600 : 1238.6317915916443\n",
            "Done for batch 650 : 1271.9221255779266\n",
            "Done for batch 700 : 1305.2256326675415\n",
            "Done for batch 750 : 1338.5047676563263\n",
            "Done for batch 800 : 1371.7924437522888\n",
            "Done for batch 850 : 1405.066261291504\n",
            "Done for batch 900 : 1438.3472633361816\n",
            "Done for batch 950 : 1471.623117685318\n",
            "Done for batch 1000 : 1504.8818664550781\n",
            "Done for batch 1050 : 1538.1638572216034\n",
            "Done for batch 1100 : 1571.462969303131\n",
            "Done for batch 1150 : 1604.7516343593597\n",
            "Done for batch 1200 : 1638.0453367233276\n",
            "Done for batch 1250 : 1671.2912828922272\n",
            "| Epoch   2 | train loss  0.13 | train acc  0.83 | val loss  0.22 | val acc  0.67 | time: 839.57s |\n",
            "| Epoch   2 | train loss   0.13 | train acc  0.829 | val loss  0.221 | val acc  0.673 | time: 839.57s |\n",
            "Done for batch 0 : 1678.869728565216\n",
            "Done for batch 50 : 1712.1294703483582\n",
            "Done for batch 100 : 1745.4155912399292\n",
            "Done for batch 150 : 1778.71036028862\n",
            "Done for batch 200 : 1811.9788701534271\n",
            "Done for batch 250 : 1845.2442541122437\n",
            "Done for batch 300 : 1878.5425777435303\n",
            "Done for batch 350 : 1911.8234791755676\n",
            "Done for batch 400 : 1945.0907318592072\n",
            "Done for batch 450 : 1978.3869655132294\n",
            "Done for batch 500 : 2011.6662983894348\n",
            "Done for batch 550 : 2044.9613230228424\n",
            "Done for batch 600 : 2078.2337510585785\n",
            "Done for batch 650 : 2111.537155866623\n",
            "Done for batch 700 : 2144.8014867305756\n",
            "Done for batch 750 : 2178.1066987514496\n",
            "Done for batch 800 : 2211.365746974945\n",
            "Done for batch 850 : 2244.6347143650055\n",
            "Done for batch 900 : 2277.9251692295074\n",
            "Done for batch 950 : 2311.1717903614044\n",
            "Done for batch 1000 : 2344.438683986664\n",
            "Done for batch 1050 : 2377.6810672283173\n",
            "Done for batch 1100 : 2410.946178674698\n",
            "Done for batch 1150 : 2444.2059993743896\n",
            "Done for batch 1200 : 2477.489168405533\n",
            "Done for batch 1250 : 2510.7482249736786\n",
            "| Epoch   3 | train loss  0.09 | train acc  0.90 | val loss  0.22 | val acc  0.69 | time: 839.37s |\n",
            "| Epoch   3 | train loss   0.09 | train acc  0.897 | val loss  0.220 | val acc  0.690 | time: 839.37s |\n",
            "Done for batch 0 : 2518.3376138210297\n",
            "Done for batch 50 : 2551.623076438904\n",
            "Done for batch 100 : 2584.9136011600494\n",
            "Done for batch 150 : 2618.172358751297\n",
            "Done for batch 200 : 2651.4608170986176\n",
            "Done for batch 250 : 2684.750858068466\n",
            "Done for batch 300 : 2718.0135180950165\n",
            "Done for batch 350 : 2751.292340993881\n",
            "Done for batch 400 : 2784.557387113571\n",
            "Done for batch 450 : 2817.868637084961\n",
            "Done for batch 500 : 2851.1336686611176\n",
            "Done for batch 550 : 2884.4004604816437\n",
            "Done for batch 600 : 2917.6601984500885\n",
            "Done for batch 650 : 2950.950582265854\n",
            "Done for batch 700 : 2984.236748456955\n",
            "Done for batch 750 : 3017.5702424049377\n",
            "Done for batch 800 : 3050.9109325408936\n",
            "Done for batch 850 : 3084.224113702774\n",
            "Done for batch 900 : 3117.511302471161\n",
            "Done for batch 950 : 3150.802034139633\n",
            "Done for batch 1000 : 3184.07284617424\n",
            "Done for batch 1050 : 3217.3776066303253\n",
            "Done for batch 1100 : 3250.649952173233\n",
            "Done for batch 1150 : 3283.918098926544\n",
            "Done for batch 1200 : 3317.178857564926\n",
            "Done for batch 1250 : 3350.45943403244\n",
            "| Epoch   4 | train loss  0.06 | train acc  0.94 | val loss  0.24 | val acc  0.76 | time: 839.56s |\n",
            "| Epoch   4 | train loss   0.06 | train acc  0.937 | val loss  0.243 | val acc  0.756 | time: 839.56s |\n",
            "Done for batch 0 : 3357.9976954460144\n",
            "Done for batch 50 : 3391.270549058914\n",
            "Done for batch 100 : 3424.55180644989\n",
            "Done for batch 150 : 3457.8380303382874\n",
            "Done for batch 200 : 3491.1150493621826\n",
            "Done for batch 250 : 3524.3695430755615\n",
            "Done for batch 300 : 3557.65637922287\n",
            "Done for batch 350 : 3590.89613366127\n",
            "Done for batch 400 : 3624.172774553299\n",
            "Done for batch 450 : 3657.4470970630646\n",
            "Done for batch 500 : 3690.717397928238\n",
            "Done for batch 550 : 3723.9962754249573\n",
            "Done for batch 600 : 3757.293165206909\n",
            "Done for batch 650 : 3790.5780165195465\n",
            "Done for batch 700 : 3823.847499370575\n",
            "Done for batch 750 : 3857.1367268562317\n",
            "Done for batch 800 : 3890.4141550064087\n",
            "Done for batch 850 : 3923.7015035152435\n",
            "Done for batch 900 : 3956.9763839244843\n",
            "Done for batch 950 : 3990.2840826511383\n",
            "Done for batch 1000 : 4023.5817935466766\n",
            "Done for batch 1050 : 4056.889266729355\n",
            "Done for batch 1100 : 4090.181791782379\n",
            "Done for batch 1150 : 4123.454206705093\n",
            "Done for batch 1200 : 4156.699416637421\n",
            "Done for batch 1250 : 4189.97718000412\n",
            "| Epoch   5 | train loss  0.04 | train acc  0.96 | val loss  0.31 | val acc  0.76 | time: 839.47s |\n",
            "| Epoch   5 | train loss   0.04 | train acc  0.959 | val loss  0.314 | val acc  0.759 | time: 839.47s |\n",
            "Done for batch 0 : 4197.560672521591\n",
            "Done for batch 50 : 4230.844341754913\n",
            "Done for batch 100 : 4264.1882655620575\n",
            "Done for batch 150 : 4297.531793117523\n",
            "Done for batch 200 : 4330.908707380295\n",
            "Done for batch 250 : 4364.2662744522095\n",
            "Done for batch 300 : 4397.62539935112\n",
            "Done for batch 350 : 4430.977937936783\n",
            "Done for batch 400 : 4464.285532474518\n",
            "Done for batch 450 : 4497.573266983032\n",
            "Done for batch 500 : 4530.876266479492\n",
            "Done for batch 550 : 4564.151107549667\n",
            "Done for batch 600 : 4597.444406747818\n",
            "Done for batch 650 : 4630.746959447861\n",
            "Done for batch 700 : 4664.03435254097\n",
            "Done for batch 750 : 4697.370615720749\n",
            "Done for batch 800 : 4730.740614414215\n",
            "Done for batch 850 : 4763.952445268631\n",
            "Done for batch 900 : 4797.140126943588\n",
            "Done for batch 950 : 4830.295116186142\n",
            "Done for batch 1000 : 4863.4468767642975\n",
            "Done for batch 1050 : 4896.597514390945\n",
            "Done for batch 1100 : 4929.755852460861\n",
            "Done for batch 1150 : 4962.916741132736\n",
            "Done for batch 1200 : 4996.071222782135\n",
            "Done for batch 1250 : 5029.230540752411\n",
            "| Epoch   6 | train loss  0.04 | train acc  0.97 | val loss  0.39 | val acc  0.70 | time: 839.13s |\n",
            "| Epoch   6 | train loss   0.04 | train acc  0.969 | val loss  0.386 | val acc  0.704 | time: 839.13s |\n",
            "Done for batch 0 : 5036.6965544223785\n",
            "Done for batch 50 : 5069.876440048218\n",
            "Done for batch 100 : 5103.04786157608\n",
            "Done for batch 150 : 5136.211557865143\n",
            "Done for batch 200 : 5169.370582103729\n",
            "Done for batch 250 : 5202.539227247238\n",
            "Done for batch 300 : 5235.696630001068\n",
            "Done for batch 350 : 5268.827966213226\n",
            "Done for batch 400 : 5301.965258598328\n",
            "Done for batch 450 : 5335.110684871674\n",
            "Done for batch 500 : 5368.282859802246\n",
            "Done for batch 550 : 5401.449661254883\n",
            "Done for batch 600 : 5434.570925235748\n",
            "Done for batch 650 : 5467.718545198441\n",
            "Done for batch 700 : 5500.857354402542\n",
            "Done for batch 750 : 5534.003946065903\n",
            "Done for batch 800 : 5567.132526397705\n",
            "Done for batch 850 : 5600.272857904434\n",
            "Done for batch 900 : 5633.384761333466\n",
            "Done for batch 950 : 5666.513560533524\n",
            "Done for batch 1000 : 5699.656099081039\n",
            "Done for batch 1050 : 5732.798344612122\n",
            "Done for batch 1100 : 5765.940722942352\n",
            "Done for batch 1150 : 5799.091991901398\n",
            "Done for batch 1200 : 5832.237557411194\n",
            "Done for batch 1250 : 5865.389888763428\n",
            "| Epoch   7 | train loss  0.03 | train acc  0.97 | val loss  0.38 | val acc  0.74 | time: 836.15s |\n",
            "| Epoch   7 | train loss   0.03 | train acc  0.973 | val loss  0.378 | val acc  0.735 | time: 836.15s |\n",
            "Done for batch 0 : 5872.845509290695\n",
            "Done for batch 50 : 5905.988564014435\n",
            "Done for batch 100 : 5939.1445553302765\n",
            "Done for batch 150 : 5972.328609466553\n",
            "Done for batch 200 : 6005.494558095932\n",
            "Done for batch 250 : 6038.601831436157\n",
            "Done for batch 300 : 6071.7447254657745\n",
            "Done for batch 350 : 6104.937250375748\n",
            "Done for batch 400 : 6137.880623102188\n",
            "Done for batch 450 : 6170.670220851898\n",
            "Done for batch 500 : 6203.439699172974\n",
            "Done for batch 550 : 6236.213265419006\n",
            "Done for batch 600 : 6268.959104537964\n",
            "Done for batch 650 : 6301.756597280502\n",
            "Done for batch 700 : 6334.5413682460785\n",
            "Done for batch 750 : 6367.355752229691\n",
            "Done for batch 800 : 6400.156520843506\n",
            "Done for batch 850 : 6432.94161605835\n",
            "Done for batch 900 : 6465.71049451828\n",
            "Done for batch 950 : 6498.4462559223175\n",
            "Done for batch 1000 : 6531.261762857437\n",
            "Done for batch 1050 : 6564.075135707855\n",
            "Done for batch 1100 : 6596.881187438965\n",
            "Done for batch 1150 : 6629.690066099167\n",
            "Done for batch 1200 : 6662.490737915039\n",
            "Done for batch 1250 : 6695.31209564209\n",
            "| Epoch   8 | train loss  0.03 | train acc  0.98 | val loss  0.43 | val acc  0.73 | time: 829.84s |\n",
            "| Epoch   8 | train loss   0.03 | train acc  0.976 | val loss  0.425 | val acc  0.731 | time: 829.84s |\n",
            "Done for batch 0 : 6702.684820890427\n",
            "Done for batch 50 : 6735.4707996845245\n",
            "Done for batch 100 : 6768.27056312561\n",
            "Done for batch 150 : 6801.050537109375\n",
            "Done for batch 200 : 6833.776743650436\n",
            "Done for batch 250 : 6866.482268571854\n",
            "Done for batch 300 : 6899.644221544266\n",
            "Done for batch 350 : 6932.983421087265\n",
            "Done for batch 400 : 6965.984530925751\n",
            "Done for batch 450 : 6998.690988302231\n",
            "Done for batch 500 : 7031.462608337402\n",
            "Done for batch 550 : 7064.218205690384\n",
            "Done for batch 600 : 7096.823058605194\n",
            "Done for batch 650 : 7129.907293319702\n",
            "Done for batch 700 : 7163.188745975494\n",
            "Done for batch 750 : 7196.082869768143\n",
            "Done for batch 800 : 7228.928596019745\n",
            "Done for batch 850 : 7261.617560386658\n",
            "Done for batch 900 : 7294.691596984863\n",
            "Done for batch 950 : 7328.004312515259\n",
            "Done for batch 1000 : 7361.108151912689\n",
            "Done for batch 1050 : 7394.021676778793\n",
            "Done for batch 1100 : 7426.9027688503265\n",
            "Done for batch 1150 : 7459.585138320923\n",
            "Done for batch 1200 : 7492.722614765167\n",
            "Done for batch 1250 : 7525.991658449173\n",
            "| Epoch   9 | train loss  0.03 | train acc  0.98 | val loss  0.51 | val acc  0.71 | time: 830.77s |\n",
            "| Epoch   9 | train loss   0.03 | train acc  0.980 | val loss  0.507 | val acc  0.715 | time: 830.77s |\n",
            "Done for batch 0 : 7533.454691171646\n",
            "Done for batch 50 : 7566.637822389603\n",
            "Done for batch 100 : 7599.783059358597\n",
            "Done for batch 150 : 7632.8652975559235\n",
            "Done for batch 200 : 7665.956064224243\n",
            "Done for batch 250 : 7699.119186639786\n",
            "Done for batch 300 : 7732.194349050522\n",
            "Done for batch 350 : 7765.31297659874\n",
            "Done for batch 400 : 7798.39114689827\n",
            "Done for batch 450 : 7831.502189397812\n",
            "Done for batch 500 : 7864.681965827942\n",
            "Done for batch 550 : 7897.8738334178925\n",
            "Done for batch 600 : 7931.026381015778\n",
            "Done for batch 650 : 7964.130232095718\n",
            "Done for batch 700 : 7997.2569851875305\n",
            "Done for batch 750 : 8030.426821231842\n",
            "Done for batch 800 : 8063.7335386276245\n",
            "Done for batch 850 : 8097.0267877578735\n",
            "Done for batch 900 : 8130.278584718704\n",
            "Done for batch 950 : 8163.53076505661\n",
            "Done for batch 1000 : 8196.795511484146\n",
            "Done for batch 1050 : 8230.038794517517\n",
            "Done for batch 1100 : 8263.286752700806\n",
            "Done for batch 1150 : 8296.536129951477\n",
            "Done for batch 1200 : 8329.7866461277\n",
            "Done for batch 1250 : 8363.00960946083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5opISLnCyTQ8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMwnEUBkyVGI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4z24PrBiYRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90a4333-f91a-4905-afac-890f214737ad"
      },
      "source": [
        "## Zip the final model and all the required files, such as vocabulary\n",
        "# Replace USERID with your own, such as 2017CSZ8058\n",
        "!zip -r 2021CSY7548_B_model.zip  /content/model/\n",
        "## Upload it to Google drive and ensure that the testing notebook uses the correct link"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/model/ (stored 0%)\n",
            "  adding: content/model/weight_params.pt (deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNdU8UB4dGe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}